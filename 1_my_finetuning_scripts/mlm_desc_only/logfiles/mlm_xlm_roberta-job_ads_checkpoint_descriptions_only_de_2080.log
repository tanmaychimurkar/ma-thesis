INFO:[mlm_description_only_checkpoint.py:55] - Starting run, using only concept descriptions for this training [2023-01-05 01:00:34,249]
INFO:[mlm_description_only_checkpoint.py:57] - Loading models and the tokenizer for the pretrained model xlm_roberta-job_ads_checkpoint [2023-01-05 01:00:34,249]
INFO:[mlm_description_only_checkpoint.py:61] - Loading raw datasets [2023-01-05 01:00:43,500]
INFO:[mlm_description_only_checkpoint.py:71] - Getting only the description subsets [2023-01-05 01:00:43,603]
INFO:[mlm_description_only_checkpoint.py:76] - Appending desc data and adding temp label column [2023-01-05 01:00:43,612]
INFO:[mlm_description_only_checkpoint.py:82] - The combined data has the columns: Index(['text', 'labels'], dtype='object'), and shape (16910, 2) [2023-01-05 01:00:43,615]
INFO:[mlm_description_only_checkpoint.py:84] - Creating the datasets Dataset object for using in the pipeline [2023-01-05 01:00:43,615]
INFO:[mlm_description_only_checkpoint.py:87] - Creating dict from the dataset [2023-01-05 01:00:43,642]
INFO:[mlm_description_only_checkpoint.py:100] - The total length of the input ids in tokenized dataset is 16910 [2023-01-05 01:00:49,315]
INFO:[mlm_description_only_checkpoint.py:103] - The length of a random input in this dataset is 17 [2023-01-05 01:00:49,706]
INFO:[mlm_description_only_checkpoint.py:105] - Setting chunk size to concat descriptions longer than 512 tokens [2023-01-05 01:00:49,706]
INFO:[mlm_description_only_checkpoint.py:125] - Formatting the datasets to keep each input of length 512 tokens [2023-01-05 01:00:49,706]
INFO:[mlm_description_only_checkpoint.py:129] - After creating chunks, below are the statistics of the data:
Initial data was in variable tokenized_dataset with total tokens being 785823, after creatingchunks, the total tokens in the dataset are 783104 [2023-01-05 01:00:54,071]
INFO:[mlm_description_only_checkpoint.py:135] - Creating train and evaluation datasets for fine-tuning [2023-01-05 01:00:54,071]
INFO:[mlm_description_only_checkpoint.py:145] - Creating the data collator class since there are only descriptions here in this case [2023-01-05 01:00:54,410]
INFO:[mlm_description_only_checkpoint.py:150] - Setting training arguments [2023-01-05 01:00:54,992]
INFO:[distributed_c10d.py:319] - Added key: store_based_barrier_key:1 to store for rank: 2 [2023-01-05 01:00:55,027]
INFO:[distributed_c10d.py:353] - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes. [2023-01-05 01:00:55,031]
INFO:[mlm_description_only_checkpoint.py:172] - Initiating trainer object [2023-01-05 01:00:55,189]
INFO:[mlm_description_only_checkpoint.py:178] - Starting training [2023-01-05 01:00:58,569]
INFO:[distributed.py:1027] - Reducer buckets have been rebuilt in this iteration. [2023-01-05 01:01:01,224]
