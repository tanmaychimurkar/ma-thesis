INFO:[mlm_description_only_checkpoint.py:55] - Starting run, using only concept descriptions for this training [2023-01-05 14:39:05,156]
INFO:[mlm_description_only_checkpoint.py:57] - Loading models and the tokenizer for the pretrained model xlm_roberta-job_ads_checkpoint [2023-01-05 14:39:05,157]
INFO:[mlm_description_only_checkpoint.py:61] - Loading raw datasets [2023-01-05 14:39:10,523]
INFO:[mlm_description_only_checkpoint.py:71] - Getting only the description subsets [2023-01-05 14:39:10,608]
INFO:[mlm_description_only_checkpoint.py:76] - Appending desc data and adding temp label column [2023-01-05 14:39:10,614]
INFO:[mlm_description_only_checkpoint.py:82] - The combined data has the columns: Index(['text', 'labels'], dtype='object'), and shape (16910, 2) [2023-01-05 14:39:10,617]
INFO:[mlm_description_only_checkpoint.py:84] - Creating the datasets Dataset object for using in the pipeline [2023-01-05 14:39:10,617]
INFO:[mlm_description_only_checkpoint.py:87] - Creating dict from the dataset [2023-01-05 14:39:10,638]
INFO:[mlm_description_only_checkpoint.py:100] - The total length of the input ids in tokenized dataset is 16910 [2023-01-05 14:39:14,479]
INFO:[mlm_description_only_checkpoint.py:103] - The length of a random input in this dataset is 17 [2023-01-05 14:39:14,982]
INFO:[mlm_description_only_checkpoint.py:105] - Setting chunk size to concat descriptions longer than 512 tokens [2023-01-05 14:39:14,982]
INFO:[mlm_description_only_checkpoint.py:125] - Formatting the datasets to keep each input of length 512 tokens [2023-01-05 14:39:14,982]
INFO:[mlm_description_only_checkpoint.py:129] - After creating chunks, below are the statistics of the data:
Initial data was in variable tokenized_dataset with total tokens being 785823, after creatingchunks, the total tokens in the dataset are 783104 [2023-01-05 14:39:19,665]
INFO:[mlm_description_only_checkpoint.py:135] - Creating train and evaluation datasets for fine-tuning [2023-01-05 14:39:19,666]
INFO:[mlm_description_only_checkpoint.py:145] - Creating the data collator class since there are only descriptions here in this case [2023-01-05 14:39:20,114]
INFO:[mlm_description_only_checkpoint.py:150] - Setting training arguments [2023-01-05 14:39:20,680]
INFO:[distributed_c10d.py:319] - Added key: store_based_barrier_key:1 to store for rank: 1 [2023-01-05 14:39:20,765]
INFO:[distributed_c10d.py:353] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes. [2023-01-05 14:39:20,771]
INFO:[mlm_description_only_checkpoint.py:171] - Initiating trainer object [2023-01-05 14:39:20,800]
INFO:[mlm_description_only_checkpoint.py:177] - Starting training [2023-01-05 14:39:23,041]
INFO:[distributed.py:1027] - Reducer buckets have been rebuilt in this iteration. [2023-01-05 14:39:25,663]
INFO:[mlm_description_only_checkpoint.py:180] - Saving best model from the best model at end config [2023-01-05 18:56:54,782]
