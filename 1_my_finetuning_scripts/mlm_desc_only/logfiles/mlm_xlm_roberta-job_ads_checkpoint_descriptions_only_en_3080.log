INFO:[mlm_description_only_checkpoint.py:55] - Starting run, using only concept descriptions for this training [2023-01-05 12:35:07,736]
INFO:[mlm_description_only_checkpoint.py:57] - Loading models and the tokenizer for the pretrained model xlm_roberta-job_ads_checkpoint [2023-01-05 12:35:07,736]
INFO:[mlm_description_only_checkpoint.py:61] - Loading raw datasets [2023-01-05 12:35:12,557]
INFO:[mlm_description_only_checkpoint.py:71] - Getting only the description subsets [2023-01-05 12:35:12,652]
INFO:[mlm_description_only_checkpoint.py:76] - Appending desc data and adding temp label column [2023-01-05 12:35:12,659]
INFO:[mlm_description_only_checkpoint.py:82] - The combined data has the columns: Index(['text', 'labels'], dtype='object'), and shape (17317, 2) [2023-01-05 12:35:12,661]
INFO:[mlm_description_only_checkpoint.py:84] - Creating the datasets Dataset object for using in the pipeline [2023-01-05 12:35:12,661]
INFO:[mlm_description_only_checkpoint.py:87] - Creating dict from the dataset [2023-01-05 12:35:12,676]
INFO:[mlm_description_only_checkpoint.py:100] - The total length of the input ids in tokenized dataset is 17317 [2023-01-05 12:35:16,051]
INFO:[mlm_description_only_checkpoint.py:103] - The length of a random input in this dataset is 16 [2023-01-05 12:35:16,477]
INFO:[mlm_description_only_checkpoint.py:105] - Setting chunk size to concat descriptions longer than 512 tokens [2023-01-05 12:35:16,477]
INFO:[mlm_description_only_checkpoint.py:125] - Formatting the datasets to keep each input of length 512 tokens [2023-01-05 12:35:16,477]
INFO:[mlm_description_only_checkpoint.py:129] - After creating chunks, below are the statistics of the data:
Initial data was in variable tokenized_dataset with total tokens being 671137, after creatingchunks, the total tokens in the dataset are 669184 [2023-01-05 12:35:20,371]
INFO:[mlm_description_only_checkpoint.py:135] - Creating train and evaluation datasets for fine-tuning [2023-01-05 12:35:20,371]
INFO:[mlm_description_only_checkpoint.py:145] - Creating the data collator class since there are only descriptions here in this case [2023-01-05 12:35:20,750]
INFO:[mlm_description_only_checkpoint.py:150] - Setting training arguments [2023-01-05 12:35:21,567]
INFO:[distributed_c10d.py:319] - Added key: store_based_barrier_key:1 to store for rank: 1 [2023-01-05 12:35:21,627]
INFO:[distributed_c10d.py:353] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes. [2023-01-05 12:35:21,636]
INFO:[mlm_description_only_checkpoint.py:171] - Initiating trainer object [2023-01-05 12:35:21,681]
INFO:[mlm_description_only_checkpoint.py:177] - Starting training [2023-01-05 12:35:23,812]
INFO:[distributed.py:1027] - Reducer buckets have been rebuilt in this iteration. [2023-01-05 12:35:26,422]
INFO:[mlm_description_only_checkpoint.py:180] - Saving best model from the best model at end config [2023-01-05 15:55:09,533]
