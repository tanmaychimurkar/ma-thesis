INFO:[mlm_description_only_checkpoint.py:55] - Starting run, using only concept descriptions for this training [2023-01-05 19:14:27,534]
INFO:[mlm_description_only_checkpoint.py:57] - Loading models and the tokenizer for the pretrained model xlm_roberta-job_ads_checkpoint [2023-01-05 19:14:27,535]
INFO:[mlm_description_only_checkpoint.py:61] - Loading raw datasets [2023-01-05 19:14:36,896]
INFO:[mlm_description_only_checkpoint.py:71] - Getting only the description subsets [2023-01-05 19:14:37,139]
INFO:[mlm_description_only_checkpoint.py:76] - Appending desc data and adding temp label column [2023-01-05 19:14:37,146]
INFO:[mlm_description_only_checkpoint.py:82] - The combined data has the columns: Index(['text', 'labels'], dtype='object'), and shape (16910, 2) [2023-01-05 19:14:37,149]
INFO:[mlm_description_only_checkpoint.py:84] - Creating the datasets Dataset object for using in the pipeline [2023-01-05 19:14:37,150]
INFO:[mlm_description_only_checkpoint.py:87] - Creating dict from the dataset [2023-01-05 19:14:37,187]
INFO:[mlm_description_only_checkpoint.py:100] - The total length of the input ids in tokenized dataset is 16910 [2023-01-05 19:14:42,657]
INFO:[mlm_description_only_checkpoint.py:103] - The length of a random input in this dataset is 17 [2023-01-05 19:14:44,243]
INFO:[mlm_description_only_checkpoint.py:105] - Setting chunk size to concat descriptions longer than 512 tokens [2023-01-05 19:14:44,243]
INFO:[mlm_description_only_checkpoint.py:125] - Formatting the datasets to keep each input of length 512 tokens [2023-01-05 19:14:44,243]
INFO:[mlm_description_only_checkpoint.py:129] - After creating chunks, below are the statistics of the data:
Initial data was in variable tokenized_dataset with total tokens being 785823, after creatingchunks, the total tokens in the dataset are 783104 [2023-01-05 19:14:48,376]
INFO:[mlm_description_only_checkpoint.py:135] - Creating train and evaluation datasets for fine-tuning [2023-01-05 19:14:48,377]
INFO:[mlm_description_only_checkpoint.py:145] - Creating the data collator class since there are only descriptions here in this case [2023-01-05 19:14:48,789]
INFO:[mlm_description_only_checkpoint.py:150] - Setting training arguments [2023-01-05 19:14:49,410]
INFO:[distributed_c10d.py:319] - Added key: store_based_barrier_key:1 to store for rank: 1 [2023-01-05 19:14:49,446]
INFO:[distributed_c10d.py:353] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes. [2023-01-05 19:14:49,452]
INFO:[mlm_description_only_checkpoint.py:171] - Initiating trainer object [2023-01-05 19:14:49,587]
INFO:[mlm_description_only_checkpoint.py:177] - Starting training [2023-01-05 19:14:53,537]
INFO:[distributed.py:1027] - Reducer buckets have been rebuilt in this iteration. [2023-01-05 19:14:56,564]
